"""
Clarification: Context Window vs Application Memory

CRITICAL DISTINCTION:
- Context Window = LLM conversation history (tokens sent to Claude)
- Application Memory = Python runtime memory (cache, variables)
"""


def explain_context_vs_memory():
    """Explain the difference between context window and memory"""

    print("=" * 70)
    print("CONTEXT WINDOW vs APPLICATION MEMORY")
    print("=" * 70)
    print()

    print("[CONCEPT 1] LLM CONTEXT WINDOW")
    print("-" * 70)
    print("What it is:")
    print("  - Conversation history sent to Claude API")
    print("  - Messages, tool calls, tool results")
    print("  - Limited to 200,000 tokens (Claude Sonnet 4.5)")
    print()
    print("What fills it:")
    print("  - User messages")
    print("  - Assistant responses")
    print("  - Tool call requests")
    print("  - Tool call results (returned data)")
    print("  - System prompts")
    print()
    print("How to clear it:")
    print("  - Start NEW conversation")
    print("  - Cannot be cleared mid-conversation")
    print("  - Grows with every message/tool call")
    print()
    print("Example:")
    print("  User: 'Get docs for langgraph'")
    print("  Claude: *calls context7 tool*")
    print("  Tool Result: {...documentation...} <- ADDED TO CONTEXT")
    print("  Claude: 'Here are the docs...'")
    print()
    print("  Context tokens: ~5,000 tokens")
    print("  These tokens STAY in context for rest of conversation!")
    print()

    print("[CONCEPT 2] APPLICATION MEMORY (Python Runtime)")
    print("-" * 70)
    print("What it is:")
    print("  - Python variables, caches, objects in RAM")
    print("  - MCPBridge._context7_cache dictionary")
    print("  - Exists in Python process only")
    print()
    print("What fills it:")
    print("  - API responses cached locally")
    print("  - Loaded tool definitions")
    print("  - Bridge state")
    print()
    print("How to clear it:")
    print("  - unload_tools('context7') <- Clears Python cache")
    print("  - bridge._context7_cache.clear()")
    print("  - Restart Python process")
    print()
    print("Example:")
    print("  bridge.call_context7_tool(...)")
    print("  Result cached in Python: bridge._context7_cache[key] = result")
    print()
    print("  unload_tools('context7')")
    print("  Python cache cleared: bridge._context7_cache = {}")
    print()
    print("  Context window: UNCHANGED (still has tool results!)")
    print()

    print("=" * 70)
    print("CRITICAL DIFFERENCE")
    print("=" * 70)
    print()
    print("Scenario: Call Context7 to get docs for 'langgraph'")
    print()

    print("BEFORE unload_tools:")
    print("  Context Window: ~5,000 tokens (tool result visible to Claude)")
    print("  Python Cache: 1 entry (for faster re-calls)")
    print()

    print("AFTER unload_tools('context7'):")
    print("  Context Window: ~5,000 tokens (UNCHANGED - Claude still sees it!)")
    print("  Python Cache: 0 entries (cleared from memory)")
    print()

    print("What unload_tools does:")
    print("  [YES] Frees Python memory")
    print("  [YES] Prevents duplicate API calls")
    print("  [NO]  Does NOT remove from Claude's context window")
    print("  [NO]  Does NOT reduce token count")
    print()

    print("=" * 70)
    print("EXAMPLE WITH TOKEN COUNTS")
    print("=" * 70)
    print()

    print("Step 1: Call Context7")
    print("  Request: 100 tokens")
    print("  Response: 2,000 tokens")
    print("  Context Window Total: 2,100 tokens")
    print("  Python Cache: 1 entry (2KB)")
    print()

    print("Step 2: unload_tools('context7')")
    print("  Context Window Total: 2,100 tokens (SAME!)")
    print("  Python Cache: 0 entries (2KB freed)")
    print()

    print("Why?")
    print("  - Tool results already sent to Claude")
    print("  - They're part of conversation history")
    print("  - Cannot be unsent or removed")
    print("  - Only way to clear: start new conversation")
    print()

    print("=" * 70)
    print("WHEN unload_tools IS USEFUL")
    print("=" * 70)
    print()

    print("Use Case 1: Memory Management")
    print("  - Context7 cache grows large (100+ entries)")
    print("  - Python process using too much RAM")
    print("  - Unload to free memory")
    print()

    print("Use Case 2: Prevent Duplicate API Calls")
    print("  - Want fresh data from Context7 API")
    print("  - Clear cache to bypass cached results")
    print("  - Next call will hit API again")
    print()

    print("Use Case 3: Session Cleanup")
    print("  - Switching between different projects")
    print("  - Different docs needed")
    print("  - Clear old cached docs")
    print()

    print("NOT USEFUL FOR:")
    print("  [X] Reducing context window tokens")
    print("  [X] Freeing LLM memory")
    print("  [X] Reducing API costs")
    print("  [X] Speeding up Claude responses")
    print()

    print("=" * 70)
    print("HOW TO ACTUALLY REDUCE CONTEXT WINDOW")
    print("=" * 70)
    print()

    print("Option 1: Start New Conversation")
    print("  - Only way to truly clear context")
    print("  - Resets token count to 0")
    print("  - Loses all conversation history")
    print()

    print("Option 2: Design for Token Efficiency")
    print("  - Use Serena (semantic search) instead of full file reads")
    print("  - Request only needed fields from Context7")
    print("  - Summarize large tool results before adding to context")
    print("  - Use references instead of copying data")
    print()

    print("Option 3: Tool Result Filtering")
    print("  - Return only essential data from tools")
    print("  - Avoid returning full documentation")
    print("  - Return IDs/references instead of full objects")
    print()

    print("=" * 70)
    print("VISUALIZING THE DIFFERENCE")
    print("=" * 70)
    print()

    print("┌─────────────────────────────────────────────────────────┐")
    print("│ LLM CONTEXT WINDOW (Claude's Memory)                   │")
    print("├─────────────────────────────────────────────────────────┤")
    print("│ User: Get docs for langgraph                           │")
    print("│ Tool Call: context7.get_package_docs(...)              │")
    print("│ Tool Result: {huge JSON with docs...}  <- 2000 tokens  │")
    print("│ Assistant: Here are the docs...                        │")
    print("│                                                         │")
    print("│ Total: 2,100 tokens                                    │")
    print("│ Status: PERSISTS until new conversation                │")
    print("└─────────────────────────────────────────────────────────┘")
    print()
    print("                      ↕ INDEPENDENT ↕")
    print()
    print("┌─────────────────────────────────────────────────────────┐")
    print("│ PYTHON APPLICATION MEMORY                               │")
    print("├─────────────────────────────────────────────────────────┤")
    print("│ bridge._context7_cache = {                             │")
    print("│   'get_package_docs:langgraph': {result...}  <- 2KB    │")
    print("│ }                                                       │")
    print("│                                                         │")
    print("│ unload_tools('context7')                               │")
    print("│ ↓                                                       │")
    print("│ bridge._context7_cache = {}  <- CLEARED                │")
    print("│                                                         │")
    print("│ Status: Cache cleared, memory freed                    │")
    print("└─────────────────────────────────────────────────────────┘")
    print()

    print("=" * 70)
    print("SUMMARY")
    print("=" * 70)
    print()
    print("Question: Does unload_tools clear from context window?")
    print("Answer: NO")
    print()
    print("What unload_tools clears:")
    print("  [YES] Python cache (Application memory)")
    print("  [YES] Tool definitions (Application state)")
    print()
    print("What unload_tools does NOT clear:")
    print("  [NO] LLM context window (Conversation history)")
    print("  [NO] Token count (API usage)")
    print("  [NO] Tool results already sent to Claude")
    print()
    print("To clear context window:")
    print("  -> Start a new conversation")
    print()
    print("=" * 70)


if __name__ == "__main__":
    explain_context_vs_memory()

    print()
    print("ANALOGY:")
    print()
    print("Context Window = Your conversation transcript with someone")
    print("  - Everything said is recorded")
    print("  - Can't unsay things")
    print("  - Can only start fresh conversation")
    print()
    print("Python Cache = Your personal notes about the conversation")
    print("  - You can erase your notes anytime")
    print("  - Doesn't change what was said")
    print("  - Helps you avoid repeating questions")
    print()
    print("unload_tools() = Erasing your notes")
    print("  - Clears YOUR memory")
    print("  - Doesn't erase the transcript")
    print("  - Other person still remembers everything")
    print()
    print("=" * 70)